{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTmlSSxmq98f"
   },
   "source": [
    "# Seminar 16 - Combinatorics, Graph, Boolean Logic\n",
    "\n",
    "## Random Networks\n",
    "\n",
    "## HW 11\n",
    "\n",
    "Please, fill in before you start:\n",
    "\n",
    "First Name:\n",
    "\n",
    "Last Name:\n",
    "\n",
    "Group:\n",
    "\n",
    "### After the assigment is done, please, push it to your [private GitHub repository](https://docs.github.com/en/github/administering-a-repository/managing-repository-settings/setting-repository-visibility) and invite [Majid-Sohrabi](https://github.com/Majid-Sohrabi)  and [Sifei-Meng](https://github.com/mengsifei) as [collaborator](https://docs.github.com/en/account-and-profile/setting-up-and-managing-your-github-user-account/managing-access-to-your-personal-repositories/inviting-collaborators-to-a-personal-repository).\n",
    "\n",
    "Complete all task and send the notebook as HW.\n",
    "\n",
    "\n",
    "- Please create a private GitHub repository and add Majid and Sifei as collaborator. Commit your solution (jupyter notebook) to your github repository.\n",
    "\n",
    "- Deadline: **May 24, 2024, 11:59 pm**.\n",
    "\n",
    "- Please keep the file name but replace **YOUR_NAME** part by your name: **[HW11_Combinatorics]-YOUR_NAME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZtkr8rcq98i"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from zlib import adler32\n",
    "import requests\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2VUnJ9kq98j"
   },
   "source": [
    "### Task 1. Erdos Renyi model (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pscgF0Yuq98k"
   },
   "source": [
    "Implement Erdos Renyi model (random graph) — each pair of $n$ nodes are connected with some fixed probability $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "DXQilLjrq98l",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e67a19e0a6ae55dd020c9103e8cc795d",
     "grade": false,
     "grade_id": "cell-4d93a39b3f69dd92",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def erdos_renyi_graph(n, p):\n",
    "    G = nx.Graph()\n",
    "    nodes = np.arange(n)\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edges_from(random_edges(nodes, p))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eF8Ovtx2q98l"
   },
   "source": [
    "Write a function `random_edges` with parameters: `nodes` — np.array of nodes, for example [1, 2, 3, 4, ...] and `p` — probability of connection. The function returns np.array with tuples of the form [(1, 2), (2, 4), ...], where 1-2, 2-4 are edges that should be added in the graph.\n",
    "\n",
    "*Hint: To speed up the generation, look at ALG.1 in the article [Efficient generation of large random networks](http://vlado.fmf.uni-lj.si/pub/networks/doc/ms/rndgen.pdf).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "h2H8WCQFq98m",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9299bda1c1e8cf204c9e0671a10db9d4",
     "grade": false,
     "grade_id": "cell-e2b1f0ebfa7b2fc3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def random_edges(nodes, p):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pcelndr1q98m",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97c12e3cf0e55cd230540dca4cc31158",
     "grade": true,
     "grade_id": "cell-d57f0727bf4b7394",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''Check the Erdos-Renyi random graph generation'''\n",
    "assert len(erdos_renyi_graph(100, 0.1).edges) > 0\n",
    "n = 100\n",
    "p = 0.4\n",
    "n_edges = n * (n-1) / 2\n",
    "q = 1 - p\n",
    "sigma = np.sqrt((p * q) / n_edges)\n",
    "assert  p - 3*sigma < random_edges(np.arange(n), p).shape[0] / n_edges < p + 3*sigma\n",
    "n = 1000\n",
    "p = 0.01\n",
    "n_edges = n * (n-1) / 2\n",
    "q = 1 - p\n",
    "sigma = np.sqrt((p * q) / n_edges)\n",
    "assert  p - 3*sigma < random_edges(np.arange(n), p).shape[0] / n_edges < p + 3*sigma\n",
    "n = 300\n",
    "p = 0.9\n",
    "n_edges = n * (n-1) / 2\n",
    "q = 1 - p\n",
    "sigma = np.sqrt((p * q) / n_edges)\n",
    "assert  p - 3*sigma < random_edges(np.arange(n), p).shape[0] / n_edges < p + 3*sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpTJY1qWq98n"
   },
   "source": [
    "Let us draw a couple of generated graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "cases = [('Subcritical regime: $p \\cdot n < 1$', n, 0.5/n), \n",
    "         ('Critical point: $p \\cdot n = 1$', n, 1/n), \n",
    "         ('Supercritacal regime: $p \\cdot n > 1$', n, 2/n), \n",
    "         ('Connected regime: $p \\cdot n > \\log(N)$', n, 6.5/n)]\n",
    "plt.figure(figsize=(12, 6 * 4))\n",
    "i = 1\n",
    "for regime, n, p in cases:\n",
    "    plt.subplot(4, 2, i)\n",
    "    G = erdos_renyi_graph(n, p)\n",
    "    nx.draw(\n",
    "        G, \n",
    "        with_labels=False, \n",
    "        node_size=20, \n",
    "        width=0.5, \n",
    "        node_color='tab:orange')\n",
    "    plt.title(regime)\n",
    "    i += 1\n",
    "    plt.subplot(4, 2, i)\n",
    "    degree_seq = [degree for (node, degree) in G.degree]\n",
    "    bins, freq = np.unique(degree_seq, return_counts=True)\n",
    "    plt.bar(bins, freq)\n",
    "    plt.xlim((-1, 14))\n",
    "    plt.title('Degree distribution')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sz-GTqePq98o"
   },
   "source": [
    "### Task 2. Degree distribution of random vs real networks (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3OwyQD7pq98o"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/network-science-course/network-science-course/main/datasets/wiki_vote.txt'\n",
    "open('wiki_vote.txt', 'wb').write(requests.get(url).content)\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/network-science-course/network-science-course/main/datasets/facebook_combined.txt'\n",
    "open('facebook_combined.txt', 'wb').write(requests.get(url).content)\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/network-science-course/network-science-course/main/datasets/collaboration_network_of_arxiv_general_relativity_category.txt'\n",
    "open('collaboration_network_of_arxiv_general_relativity_category.txt', 'wb').write(requests.get(url).content);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCnCn5OYq98p"
   },
   "source": [
    "Let us compare degree distributions of real and random networks and decide whether they are close or not.\n",
    "\n",
    "Write a function `random_from_real` that takes a graph and returns a random network that has the same average node degree and the same number of nodes as a given network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "5uMID0Plq98q",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a08c8750814441fab232f64de4b5d569",
     "grade": false,
     "grade_id": "cell-92113b6a2ff4c1f8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def random_from_real(graph): \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in ['wiki_vote.txt', \n",
    "             'collaboration_network_of_arxiv_general_relativity_category.txt', \n",
    "             'facebook_combined.txt']:\n",
    "    real_net = nx.read_edgelist(file)\n",
    "    random_net = random_from_real(real_net)\n",
    "    av_degree_random = np.mean(list(dict(random_net.degree).values()))\n",
    "    av_degree_real = np.mean(list(dict(real_net.degree).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2oZ9xOFgq98q",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a56733b96a2608cc23054f048db3b25",
     "grade": true,
     "grade_id": "cell-59eb008aa4354142",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for file in ['wiki_vote.txt', \n",
    "             'collaboration_network_of_arxiv_general_relativity_category.txt', \n",
    "             'facebook_combined.txt']:\n",
    "    real_net = nx.read_edgelist(file)\n",
    "    random_net = random_from_real(real_net)\n",
    "    av_degree_random = np.mean(list(dict(random_net.degree).values()))\n",
    "    av_degree_real = np.mean(list(dict(real_net.degree).values()))\n",
    "    assert len(random_net) == len(real_net)\n",
    "    assert np.abs(av_degree_random - av_degree_real) < 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = [['Wikipedia votes', 'wiki_vote.txt'], \n",
    "         ['Collaboration network', 'collaboration_network_of_arxiv_general_relativity_category.txt'], \n",
    "         ['Facebook', 'facebook_combined.txt']]\n",
    "for title, file in cases:\n",
    "    real_net = nx.read_edgelist(file)\n",
    "    random_net = random_from_real(real_net)\n",
    "    degree_hist = np.array(nx.degree_histogram(random_net))\n",
    "    idx = np.argwhere(degree_hist > 0)\n",
    "    plt.scatter(idx, degree_hist[idx], s=10, label='Random network')\n",
    "    degree_hist = np.array(nx.degree_histogram(real_net))\n",
    "    idx = np.argwhere(degree_hist > 0)\n",
    "    plt.scatter(idx, degree_hist[idx], s=10, label='Real network')\n",
    "    plt.legend()\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('p(k)')\n",
    "    plt.title(title)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real graph is poorly described by random graph. Becasue Erdos Renyi model does not contain scale free network. But in real world graph we have scale free network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFUGgGYDq98r"
   },
   "source": [
    "### Task 3. Component sizes (2 points)  -- FOR HW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xvgKmvQq98r"
   },
   "source": [
    "Let us see how the size of small components (small — not giant) depends on the probability near the critical point: $p =1/n$.\n",
    "\n",
    "Write a function `small_component_size` with parameters `n` — number of nodes, `probabilities` — np.array of probabilities. The function generates a random graph for each probability and returns np.array of average sizes of small components.\n",
    "\n",
    "*Hint: to find nodes in components, use `nx.connected_components(graph)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "BtP2KjOBq98s",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "562105a14eb97386f2d555fec24971a1",
     "grade": false,
     "grade_id": "cell-c44a46b500972535",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def small_component_size(n, probabilities):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WkvoSSVJq98s",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e51bb46c644b5b8aa8e41535948635d",
     "grade": true,
     "grade_id": "cell-7ebf6fbd6f5dd008",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "p_space = np.linspace(0.01/n, 2.5/n, 50)\n",
    "sizes = []\n",
    "for _ in range(5):\n",
    "    size = small_component_size(n, p_space)\n",
    "    assert size.shape == (50,)\n",
    "    sizes.append(size)\n",
    "\n",
    "av_sizes = np.mean(sizes, axis=0)\n",
    "assert av_sizes[0] < av_sizes[np.argmin(np.abs(p_space*n - 1))]\n",
    "assert av_sizes[49] < av_sizes[np.argmin(np.abs(p_space*n - 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.plot(p_space*n, sizes[i], c='tab:blue', alpha=0.5)\n",
    "plt.plot([1, 1], [1, 2.6], 'k--', label='Critical point')\n",
    "plt.xlabel('<k>')\n",
    "plt.ylabel('Average size of small components')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9deMG1qEq98t"
   },
   "source": [
    "Also let us see how the size of a giant component depends on the probability near the critical point.\n",
    "\n",
    "Write a function `giant_component_size` with parameters `n` — number of nodes, `probabilities` — np.array of probabilities. The function generates a random graph for each probability and returns np.array of sizes of a giant component.\n",
    "\n",
    "*Hint: to find nodes in a ginat component, use `max(nx.connected_components(graph), key=len)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "t5xTzWSIq98u",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0819a0c56cf2b22a7584e2f6784e94c4",
     "grade": false,
     "grade_id": "cell-aac3a4965109b67f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def giant_component_size(n, probabilities):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "aLB5vPf2q98u",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c53e2e0d6386b1a8295441b8daaece54",
     "grade": true,
     "grade_id": "cell-4183154a87c82a6e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "p_space = np.linspace(0.01/n, 2.5/n, 50)\n",
    "sizes = []\n",
    "for _ in range(5):\n",
    "    size = giant_component_size(n, p_space)\n",
    "    assert size.shape == (50,)\n",
    "    sizes.append(size)\n",
    "\n",
    "av_sizes = np.mean(sizes, axis=0)\n",
    "assert av_sizes[0] < 20\n",
    "assert 20 < av_sizes[np.argmin(np.abs(p_space*n - 1))] < 150\n",
    "assert 700 < av_sizes[np.argmin(np.abs(p_space*n - 2))] < 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.plot(p_space*n, sizes[i], c='tab:blue', alpha=0.5)\n",
    "plt.plot([1, 1], [0, 1000], 'k--', label='Critical point')\n",
    "plt.xlabel('<k>')\n",
    "plt.ylabel('Size of a giant component')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i01zW8pgq98v"
   },
   "source": [
    "### Task 4. Average path length of random networks (1 point)  -- FOR HW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Itqu8lHbq98v"
   },
   "source": [
    "In this task, we consider whether a random network is capable to model the small world phenomenon, also known as six degrees of separation — the distance between two randomly chosen nodes in a network is short. In other words, the average path length between two randomly chosen nodes increases in a growing network, but not so fast as the number of nodes.\n",
    "\n",
    "Write a function `growing_path_len` with parameters: `av_node_degree` is an average node degree and `n_nodes` is a np.array of numbers of nodes. The function generates a random network for each number of nodes and returns a np.array of average path lengths.\n",
    "\n",
    "*Hints:*\n",
    "* *To calculate average path length, use `nx.average_shortest_path_length`*\n",
    "* *Consider a giant component only*\n",
    "* *To find nodes in a ginat component, use `max(nx.connected_components(graph), key=len)`*\n",
    "* *To create a subgraph, use `graph.subgraph(nodes).copy()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "uRtGaULzq98w",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f530456d83f507953b14b9b7db573ce5",
     "grade": false,
     "grade_id": "cell-e15b2b6fa514857e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def growing_path_len(av_node_degree, n_nodes):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "a1zQRXH4q98w",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b6f8d0de536a24bf9ae8f6840ca6289",
     "grade": true,
     "grade_id": "cell-ce599f81a9578da6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n_nodes = np.arange(100, 1100, 100)\n",
    "av_node_degree = 50\n",
    "lengths = growing_path_len(av_node_degree, n_nodes)\n",
    "\n",
    "assert lengths.shape == (10,)\n",
    "assert 1.4 < lengths[0] < 1.6\n",
    "assert 1.9 < lengths[5] < 1.95\n",
    "assert 2 < lengths[9] < 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_nodes, lengths)\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('Average path length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiaHNmCcq98x"
   },
   "source": [
    "As we see, the small world phenomenon holds — the average path length increases at most logarithmically with respect to the number of nodes. Theoretically, the average path length $\\langle d \\rangle$ in a random network is\n",
    "\n",
    "$$\\langle d \\rangle \\approx \\frac{\\ln N}{\\ln \\langle k \\rangle}$$\n",
    "\n",
    "that corresponds to some real scale-free networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4sGIu_mq98x"
   },
   "source": [
    "### Task 5. Clustering coefficients of random vs real networks (2 + 0.5 bonus points)  -- FOR HW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oITkQveqq98y"
   },
   "source": [
    "Clustering coefficient of a node $C_i$ contains information about relationship between nearest neighbors.  $C_i = 0$ means that there is no links between neighbors and $C_i = 1$ means that there are all possible links between them. Clustering coefficient of an Erdos-Renyi random graph is equal to the probability $p$ and does not dependent of a node and its degree:\n",
    "\n",
    "$$C_i = \\langle C \\rangle = \\frac{\\langle k \\rangle}{n} = p $$\n",
    "\n",
    "Let us check it on generated data.\n",
    "\n",
    "Write a function `node_degree_clustering` with parameters `n, p` — number of nodes and probability. The function generates Erdos-Renyi random graph and returns a tuple with two np.arrays: degrees and clustering coefficients. Ordering of elements should coincide: the first degree and first clustering coefficient are related to the first node and so on.\n",
    "\n",
    "*Hint: to calculate clustering coefficients, use `nx.clustering(graph)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "7LlkhY_rq98y",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf35c671b6a9160182ee78ebdf178a1b",
     "grade": false,
     "grade_id": "cell-965e3d1a8f46e95d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def node_degree_clustering(n, p):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4YIp3JSZq98y",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a7eea7701228a2275f35750f6d5bc66",
     "grade": true,
     "grade_id": "cell-a0312f4517f72a06",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "p = 0.9\n",
    "n = 100\n",
    "degree, clustering = node_degree_clustering(n, p)\n",
    "assert degree.shape == clustering.shape\n",
    "assert clustering.mean() - 3*clustering.std() < p < clustering.mean() + 3*clustering.std()\n",
    "assert degree.mean() - 3*degree.std() < p * n < degree.mean() + 3*degree.std()\n",
    "p = 0.1\n",
    "n = 1000\n",
    "degree, clustering = node_degree_clustering(n, p)\n",
    "assert degree.shape == clustering.shape\n",
    "assert clustering.mean() - 3*clustering.std() < p < clustering.mean() + 3*clustering.std()\n",
    "assert degree.mean() - 3*degree.std() < p * n < degree.mean() + 3*degree.std()\n",
    "p = 0.01\n",
    "n = 3000\n",
    "degree, clustering = node_degree_clustering(n, p)\n",
    "assert degree.shape == clustering.shape\n",
    "assert clustering.mean() - 3*clustering.std() < p < clustering.mean() + 3*clustering.std()\n",
    "assert degree.mean() - 3*degree.std() < p * n < degree.mean() + 3*degree.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "my_AAo_Mq98z"
   },
   "source": [
    "Let us draw the dependency between node degree and clustering coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.1\n",
    "n = 1000\n",
    "degree, clustering = node_degree_clustering(n, p)\n",
    "plt.scatter(degree, clustering, s=15, linewidths=0.3)\n",
    "plt.plot([degree.min(), degree.max()], [p, p], 'k--', label='Probability')\n",
    "plt.xlabel('Node degree')\n",
    "plt.ylabel('Clustering coefficient')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyoM3Q72q98z"
   },
   "source": [
    "Let us look at the dependency of a some real social network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = np.loadtxt(\n",
    "    'https://raw.githubusercontent.com/network-science-course/network-science-course/main/datasets/real_net_degree.txt'\n",
    ")\n",
    "clustering = np.loadtxt(\n",
    "    'https://raw.githubusercontent.com/network-science-course/network-science-course/main/datasets/real_net_clustering.txt'\n",
    ")\n",
    "plt.scatter(degree, clustering, s=15, linewidths=0.3)\n",
    "plt.xlabel('Node degree')\n",
    "plt.ylabel('Clustering coefficient')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfuVnoV8q980"
   },
   "source": [
    "We can see that the average clustering coefficient slightly decreases in high degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufkcAeK8q980"
   },
   "source": [
    "### Task 6. Fitting parameters of degree distribution (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvW0OcOOq980"
   },
   "source": [
    "In the Erdos-Renyi model, we can estimate a degree distribution using the binomial distribution. The binomial distribution $B(n, p)$ converges to the Poisson $\\text{Pois}(\\lambda)$ when the number of samples $n$ tends to infinity with the fixed product $np = \\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "Vnd4d9YWq981",
    "outputId": "4e9ac0ac-64aa-4adb-dfd8-824d9a72a738"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14, 4])\n",
    "for i, [n, mean] in enumerate([[100, 50], [200, 50], [1000, 50]]):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.plot(st.binom(n, mean / n).pmf(np.arange(100)), \n",
    "             label=\"Binomial\")\n",
    "    plt.plot(st.poisson(mean).pmf(np.arange(100)), \n",
    "             label=\"Poisson\")\n",
    "    plt.xlim(20, 80)\n",
    "    plt.ylim(0, 0.1)\n",
    "    plt.title('n={}, p={:.2f}'.format(n, mean / n))\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ta0NgcCiq981"
   },
   "source": [
    "In this task we will estimate properties of Binomial and Poisson distributions and compare in what cases it is better to use Binomial.\n",
    "\n",
    "Write a function `estimate_binomial` that takes a random graph and returns binomial parameters `n` and `p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "AmypNd7Sq981",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "286fbff1f265625df5d92a55433c6021",
     "grade": false,
     "grade_id": "cell-fd6342c245c850c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def estimate_binomial(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "DKoaYCVEq981",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c182b580b2ba7a85155797f273e67f3",
     "grade": true,
     "grade_id": "cell-85182880379dd313",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "G = erdos_renyi_graph(100, 0.5)\n",
    "n, p = estimate_binomial(G)\n",
    "assert abs(p - 0.5) <= 0.05\n",
    "assert n == 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfDhsiKjq982"
   },
   "source": [
    "Write a function `estimate_poisson` that takes a random graph and returns the Poisson parameter $\\lambda$ (here denoted as `m`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "VFu_zxi3q982",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdcf6444e581e509d2072ae4b8be17ad",
     "grade": false,
     "grade_id": "cell-f3707ddb089d8ed3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def estimate_poisson(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Ok0i2qRNq982",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37d2bf7ca16fb140e0fcad1a21f7c874",
     "grade": true,
     "grade_id": "cell-f3b40f87622a45fd",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "G = erdos_renyi_graph(1000, 0.05)\n",
    "m = estimate_poisson(G)\n",
    "assert abs(m - 50) <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7foclU0q982"
   },
   "outputs": [],
   "source": [
    "def plot_distribution(ax, n, p):\n",
    "    G = erdos_renyi_graph(n, p)\n",
    "    ax.set_title(f\"n={n}, p={p}\")\n",
    "    degree_hist = np.array(nx.degree_histogram(G)) / len(G)\n",
    "    idx = np.argwhere(degree_hist > 0)\n",
    "    ax.scatter(idx, degree_hist[idx],\n",
    "               c=\"C2\", label=\"Empirical\")\n",
    "    degree_seq = np.array(list(dict(G.degree).values()))\n",
    "    k_space = np.arange(degree_seq.min(), degree_seq.max())\n",
    "    ax.plot(k_space, \n",
    "            st.binom(*estimate_binomial(G)).pmf(k_space), \n",
    "            label=\"Binomial\")\n",
    "    ax.plot(k_space, \n",
    "            st.poisson(estimate_poisson(G)).pmf(k_space), \n",
    "            label=\"Poisson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=[12, 8])\n",
    "ax = f.subplots(2, 2)\n",
    "plot_distribution(ax[0][0], 400, 0.5)\n",
    "plot_distribution(ax[0][1], 400, 0.125)\n",
    "plot_distribution(ax[1][0], 1000, 0.7)\n",
    "plot_distribution(ax[1][1], 10000, 0.005)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sparse network it's better to use Poisson distribution (right figuers). But in Dense network it better way to use Binomial distribution (left figuers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d75UjwPq983"
   },
   "source": [
    "### Task 7. Snobbish Networks (2 + 0.5 bonus points) -- FOR HW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwtk50wEq983"
   },
   "source": [
    "Consider a network of $N$ red and $N$ blue nodes. The probability that there is a link between nodes of identical color is $p$ and the probability that there is a link between nodes of different color is $q$. A network is snobbish if $p>q$, capturing a tendency to connect to nodes of the same color. For $q = 0$ the network has at least two components, containing nodes with the same color.\n",
    "\n",
    "Write a function `snobbish_network` that takes the number of red (or blue) nodes `n`, probability of link between nodes of the same color `p` and probability of link between nodes of different color `q`. The function returns a network with $2N$ nodes where every node has an attribute `color` that can be `blue` or `red`.\n",
    "\n",
    "*Hint: to set node attributes, use `nx.set_node_attributes`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "RghM8_UXq983",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c33036d546a891252b9a8a1af4dbdf7",
     "grade": false,
     "grade_id": "cell-4f50e33c87484848",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def snobbish_network(n, p, q):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1o39dX2mq984",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6c5bda7ca4340723349b72f7c18fb43",
     "grade": true,
     "grade_id": "cell-0d8fbdb837d4ddc3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sn_net = snobbish_network(100, 0.1, 0.01)\n",
    "assert sn_net.number_of_nodes() == 200\n",
    "assert set(nx.get_node_attributes(sn_net, 'color').values()) == {'blue', 'red'}\n",
    "assert np.sum(np.array(list(nx.get_node_attributes(sn_net, 'color').values())) == 'red') == 100\n",
    "assert 0.76 < nx.attribute_assortativity_coefficient(sn_net, 'color') < 0.88\n",
    "sn_net = snobbish_network(200, 0.1, 0.05)\n",
    "assert 0.25 < nx.attribute_assortativity_coefficient(sn_net, 'color') < 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_net = snobbish_network(100, 0.1, 0.01)\n",
    "nx.draw(sn_net, \n",
    "        node_color=nx.get_node_attributes(sn_net, 'color').values(), \n",
    "        node_size=100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NS_HW3_Majid_Sohrabi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
